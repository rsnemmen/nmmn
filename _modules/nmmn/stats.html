<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>nmmn.stats &#8212; nmmn  documentation</title>
    
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="nmmn  documentation" href="../../index.html" />
    <link rel="up" title="Module code" href="../index.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for nmmn.stats</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Statistical methods</span>
<span class="sd">=====================</span>

<span class="sd">- fit residuals</span>
<span class="sd">- Computing prediction and confidence bands</span>
<span class="sd">- Comparing goodness-of-fit of different models</span>
<span class="sd">- operations on statistical distributions</span>
<span class="sd">- custom statistical distributions</span>
<span class="sd">- p-values and significance</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span><span class="o">,</span><span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>




<span class="c1"># Residuals of a fit</span>
<span class="c1"># ===================</span>
<span class="c1"># Residual sum of squares, raw scatter about best-fit and </span>
<span class="c1"># intrinsic scatter.</span>

<div class="viewcode-block" id="scatterfit"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.scatterfit">[docs]</a><span class="k">def</span> <span class="nf">scatterfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">a</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Compute the mean deviation of the data about the linear model given if A,B</span>
<span class="sd">(*y=ax+b*) provided as arguments. Otherwise, compute the mean deviation about </span>
<span class="sd">the best-fit line.</span>

<span class="sd">:param x,y: assumed to be Numpy arrays. </span>
<span class="sd">:param a,b: scalars.</span>
<span class="sd">:rtype: float sd with the mean deviation.</span>
<span class="sd">	&quot;&quot;&quot;</span>

	<span class="k">if</span> <span class="n">a</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>	
		<span class="c1"># Performs linear regression</span>
		<span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
	
	<span class="c1"># Std. deviation of an individual measurement (Bevington, eq. 6.15)</span>
	<span class="n">N</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	<span class="n">sd</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">sd</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sd</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">sd</span></div>
	

<div class="viewcode-block" id="scatterfitg"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.scatterfitg">[docs]</a><span class="k">def</span> <span class="nf">scatterfitg</span><span class="p">(</span><span class="n">ydata</span><span class="p">,</span><span class="n">ymod</span><span class="p">,</span><span class="n">deg</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Compute the mean deviation of the data about the model given in</span>
<span class="sd">the array ymod, tabulated exactly like ydata.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; sd=scatterfitg(ydata,ymod,n)</span>

<span class="sd">  :param ydata : data</span>
<span class="sd">  :param ymod: model evaluated at xdata</span>
<span class="sd">  :param n: number of free parameters in the model</span>
<span class="sd">  </span>
<span class="sd">:type ydata,ymod: Numpy arrays</span>
<span class="sd">:rtype: float sd with the mean deviation.</span>
<span class="sd">	&quot;&quot;&quot;</span>	
	<span class="c1"># Std. deviation of an individual measurement (Bevington, eq. 6.15)</span>
	<span class="n">N</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span>
	<span class="n">sd</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">deg</span><span class="p">)</span><span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">ydata</span><span class="o">-</span><span class="n">ymod</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">sd</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sd</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">sd</span></div>



<div class="viewcode-block" id="scatpratt"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.scatpratt">[docs]</a><span class="k">def</span> <span class="nf">scatpratt</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This is an alternative way of computing the &quot;raw&quot; scatter about the best-fit </span>
<span class="sd">linear relation in the presence of measurement errors, proposed by </span>
<span class="sd">Pratt et al. 2009, A&amp;A, 498, 361. </span>

<span class="sd">In the words of Cavagnolo et al. (2010): </span>
<span class="sd">*We have quantified the total scatter about the best-fit relation using a </span>
<span class="sd">weighted estimate of the orthogonal distances to the best-fit line (see </span>
<span class="sd">Pratt et al. 2009).*</span>
<span class="sd">	</span>
<span class="sd">Usage:</span>

<span class="sd">.. function:: sd=scatpratt(x,y,errx,erry,a,b)</span>

<span class="sd">  :param x,y: X and Y data arrays</span>
<span class="sd">  :param errx, erry: standard deviations in X and Y</span>
<span class="sd">  :param a,b: slope and intercept of best-fit linear relation</span>
<span class="sd">  :rtype: float sd with the scatter about the best-fit.</span>

<span class="sd">v1 Mar 20 2012</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">N</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	
	<span class="c1"># Equation 4 from Pratt et al. 2009</span>
	<span class="n">sdsq</span><span class="o">=</span><span class="n">erry</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">errx</span><span class="o">**</span><span class="mi">2</span>
	<span class="n">wden</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="n">N</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="n">sdsq</span><span class="p">)</span>	<span class="c1"># Denominator of w</span>
	<span class="n">w</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="n">sdsq</span><span class="o">/</span><span class="n">wden</span>
	
	<span class="c1"># Equation 3 from Pratt et al. 2009</span>
	<span class="n">sdrawsq</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">sdraw</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sdrawsq</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">sdraw</span></div>



<div class="viewcode-block" id="residual"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.residual">[docs]</a><span class="k">def</span> <span class="nf">residual</span><span class="p">(</span><span class="n">ydata</span><span class="p">,</span><span class="n">ymod</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Compute the residual sum of squares (RSS) also known as the sum of </span>
<span class="sd">squared residuals (see http://en.wikipedia.org/wiki/Residual_sum_of_squares).</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; rss=residual(ydata,ymod)</span>

<span class="sd">where</span>
<span class="sd">  ydata : data</span>
<span class="sd">  ymod : model evaluated at xdata</span>
<span class="sd">  </span>
<span class="sd">ydata,ymod assumed to be Numpy arrays. </span>
<span class="sd">Returns the float rss with the mean deviation.</span>

<span class="sd">Dec. 2011</span>
<span class="sd">	&quot;&quot;&quot;</span>	
	<span class="c1"># Std. deviation of an individual measurement (Bevington, eq. 6.15)</span>
	<span class="n">N</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span>
	<span class="n">rss</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">ydata</span><span class="o">-</span><span class="n">ymod</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">rss</span></div>



<div class="viewcode-block" id="chisq"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.chisq">[docs]</a><span class="k">def</span> <span class="nf">chisq</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">a</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">sd</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Returns the chi-square error statistic as the sum of squared errors between</span>
<span class="sd">Y(i) and AX(i) + B. If individual standard deviations (array sd) are supplied, </span>
<span class="sd">then the chi-square error statistic is computed as the sum of squared errors</span>
<span class="sd">divided by the standard deviations.	Inspired on the IDL procedure linfit.pro.</span>
<span class="sd">See http://en.wikipedia.org/wiki/Goodness_of_fit for reference.</span>
<span class="sd">	</span>
<span class="sd">If a linear model is not provided via A,B (y=ax+b) then the method computes</span>
<span class="sd">the chi-square using the best-fit line.</span>

<span class="sd">x,y,sd assumed to be Numpy arrays. a,b scalars.</span>
<span class="sd">Returns the float chisq with the chi-square statistic.</span>
<span class="sd">	&quot;&quot;&quot;</span>

	<span class="k">if</span> <span class="n">a</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>	
		<span class="c1"># Performs linear regression</span>
		<span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
	
	<span class="c1"># Chi-square statistic (Bevington, eq. 6.9)</span>
	<span class="k">if</span> <span class="n">sd</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="n">sd</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
	
	<span class="k">return</span> <span class="n">chisq</span></div>




<div class="viewcode-block" id="chisqg"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.chisqg">[docs]</a><span class="k">def</span> <span class="nf">chisqg</span><span class="p">(</span><span class="n">ydata</span><span class="p">,</span><span class="n">ymod</span><span class="p">,</span><span class="n">sd</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Returns the chi-square error statistic as the sum of squared errors between</span>
<span class="sd">Ydata(i) and Ymodel(i). If individual standard deviations (array sd) are supplied, </span>
<span class="sd">then the chi-square error statistic is computed as the sum of squared errors</span>
<span class="sd">divided by the standard deviations.	Inspired on the IDL procedure linfit.pro.</span>
<span class="sd">See http://en.wikipedia.org/wiki/Goodness_of_fit for reference.</span>

<span class="sd">x,y,sd assumed to be Numpy arrays. a,b scalars.</span>
<span class="sd">Returns the float chisq with the chi-square statistic.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c1"># Chi-square statistic (Bevington, eq. 6.9)</span>
	<span class="k">if</span> <span class="n">sd</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">ydata</span><span class="o">-</span><span class="n">ymod</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">((</span><span class="n">ydata</span><span class="o">-</span><span class="n">ymod</span><span class="p">)</span><span class="o">/</span><span class="n">sd</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
	
	<span class="k">return</span> <span class="n">chisq</span></div>






<div class="viewcode-block" id="chisqxy"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.chisqxy">[docs]</a><span class="k">def</span> <span class="nf">chisqxy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Returns the chi-square error statistic for a linear fit, </span>
<span class="sd">computed taking into account the errors in both X and Y (i.e. the</span>
<span class="sd">effective variance). See equation 3 in Ascenso et al. 2012, A&amp;A or</span>
<span class="sd">Yee &amp; Ellingson 2003 ApJ.</span>

<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; chisq=chisqxy(xdata,ydata,errx,erry,a,b)</span>
<span class="sd">where</span>
<span class="sd">  xdata,ydata : data</span>
<span class="sd">  errx,erry : measurement uncertainties in the data</span>
<span class="sd">  a,b : slope and intercept of the best-fit linear regression model</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">sdsq</span><span class="o">=</span><span class="n">erry</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">errx</span><span class="o">**</span><span class="mi">2</span>
	<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">sdsq</span> <span class="p">)</span>
	
	<span class="k">return</span> <span class="n">chisq</span></div>





<div class="viewcode-block" id="intscat"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.intscat">[docs]</a><span class="k">def</span> <span class="nf">intscat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Estimates the intrinsic scatter about the best-fit, taking into account</span>
<span class="sd">the errors in X and Y and the &quot;raw&quot; scatter. Inspired by Pratt et al. 2009,</span>
<span class="sd">A&amp;A, 498, 361. </span>
<span class="sd">	</span>
<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; sd=intscat(x,y,errx,erry,a,b)</span>
<span class="sd">where</span>
<span class="sd">  x,y : X and Y data arrays</span>
<span class="sd">  errx, erry : standard deviations in X and Y</span>
<span class="sd">  a,b : slope and intercept of best-fit linear relation</span>
<span class="sd">  </span>
<span class="sd">Returns the float sd with the scatter about the best-fit.</span>

<span class="sd">v1 Apr 9th 2012</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c1"># Raw scatter</span>
	<span class="n">sdraw</span><span class="o">=</span><span class="n">scatpratt</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
	<span class="n">sdrawsq</span><span class="o">=</span><span class="n">sdraw</span><span class="o">**</span><span class="mi">2</span>
	
	<span class="c1"># Statistical variance, eq. 4 from Pratt et al. 2009</span>
	<span class="n">sdsq</span><span class="o">=</span><span class="n">erry</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">errx</span><span class="o">**</span><span class="mi">2</span>
	
	<span class="c1"># Intrinsic scatter for each data point</span>
	<span class="n">intscati</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sdsq</span><span class="o">-</span><span class="n">sdrawsq</span><span class="p">)</span> <span class="p">)</span>
	
	<span class="k">return</span> <span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">intscati</span><span class="p">)</span></div>
	
	


<div class="viewcode-block" id="linregress_error"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.linregress_error">[docs]</a><span class="k">def</span> <span class="nf">linregress_error</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Compute the uncertainties in the parameters A,B of the least-squares</span>
<span class="sd">linear regression fit y=ax+b to the data (scipy.stats.linregress).</span>

<span class="sd">x,y assumed to be Numpy arrays.</span>
<span class="sd">Returns the sequence sigma_a, sigma_b with the standard deviations in A and B.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	
	<span class="c1"># Performs linear regression</span>
	<span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
	
	<span class="c1"># Std. deviation of an individual measurement (Bevington, eq. 6.15)</span>
	<span class="n">N</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	<span class="n">sd</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">);</span>	<span class="n">sd</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sd</span><span class="p">)</span>
	
	<span class="c1"># Std. deviation in parameters</span>
	<span class="n">Delta</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>	<span class="c1"># Bevington, eq. 6.13</span>
	<span class="n">sdb</span><span class="o">=</span><span class="n">sd</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">Delta</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">);</span>	<span class="n">sdb</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sdb</span><span class="p">)</span>	<span class="c1"># Bevington, eq. 6.23</span>
	<span class="n">sda</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">sd</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">Delta</span><span class="p">;</span>	<span class="n">sda</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sda</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">sda</span><span class="p">,</span><span class="n">sdb</span></div>
		
	










	


<span class="c1"># Computing prediction and confidence bands</span>
<span class="c1"># ===========================================</span>
<span class="c1">#</span>
<span class="c1">#</span>


<div class="viewcode-block" id="confband"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.confband">[docs]</a><span class="k">def</span> <span class="nf">confband</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="n">yd</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">conf</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculates the confidence band of the linear regression model at the desired confidence</span>
<span class="sd">level, using analytical methods. The 2sigma confidence interval is 95% sure to contain </span>
<span class="sd">the best-fit regression line. This is not the same as saying it will contain 95% of </span>
<span class="sd">the data points.</span>

<span class="sd">Arguments:</span>
<span class="sd">- conf: desired confidence level, by default 0.95 (2 sigma)</span>
<span class="sd">- xd,yd: data arrays</span>
<span class="sd">- a,b: linear fit parameters as in y=ax+b</span>
<span class="sd">- x: (optional) array with x values to calculate the confidence band. If none is provided, will</span>
<span class="sd">  by default generate 100 points in the original x-range of the data.</span>
<span class="sd">  </span>
<span class="sd">Returns:</span>
<span class="sd">Sequence (lcb,ucb,x) with the arrays holding the lower and upper confidence bands </span>
<span class="sd">corresponding to the [input] x array.</span>

<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; lcb,ucb,x=nemmen.confband(all.kp,all.lg,a,b,conf=0.95)</span>
<span class="sd">calculates the confidence bands for the given input arrays</span>

<span class="sd">&gt;&gt;&gt; pylab.fill_between(x, lcb, ucb, alpha=0.3, facecolor=&#39;gray&#39;)</span>
<span class="sd">plots a shaded area containing the confidence band</span>

<span class="sd">References:</span>
<span class="sd">1. http://en.wikipedia.org/wiki/Simple_linear_regression, see Section Confidence intervals</span>
<span class="sd">2. http://www.weibull.com/DOEWeb/confidence_intervals_in_simple_linear_regression.htm</span>

<span class="sd">v1 Dec. 2011</span>
<span class="sd">v2 Jun. 2012: corrected bug in computing dy</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="o">-</span><span class="n">conf</span>	<span class="c1"># significance</span>
	<span class="n">n</span><span class="o">=</span><span class="n">xd</span><span class="o">.</span><span class="n">size</span>	<span class="c1"># data sample size</span>

	<span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span> <span class="n">x</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xd</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">xd</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">100</span><span class="p">)</span>

	<span class="c1"># Predicted values (best-fit model)</span>
	<span class="n">y</span><span class="o">=</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span>

	<span class="c1"># Auxiliary definitions</span>
	<span class="n">sd</span><span class="o">=</span><span class="n">scatterfit</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="n">yd</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>	<span class="c1"># Scatter of data about the model</span>
	<span class="n">sxd</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">xd</span><span class="o">-</span><span class="n">xd</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">sx</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">xd</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span>	<span class="c1"># array</span>

	<span class="c1"># Quantile of Student&#39;s t distribution for p=1-alpha/2</span>
	<span class="n">q</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mf">2.</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

	<span class="c1"># Confidence band</span>
	<span class="n">dy</span><span class="o">=</span><span class="n">q</span><span class="o">*</span><span class="n">sd</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="mf">1.</span><span class="o">/</span><span class="n">n</span> <span class="o">+</span> <span class="n">sx</span><span class="o">/</span><span class="n">sxd</span> <span class="p">)</span>
	<span class="n">ucb</span><span class="o">=</span><span class="n">y</span><span class="o">+</span><span class="n">dy</span>	<span class="c1"># Upper confidence band</span>
	<span class="n">lcb</span><span class="o">=</span><span class="n">y</span><span class="o">-</span><span class="n">dy</span>	<span class="c1"># Lower confidence band</span>

	<span class="k">return</span> <span class="n">lcb</span><span class="p">,</span><span class="n">ucb</span><span class="p">,</span><span class="n">x</span></div>
	
	
	
	
	
<div class="viewcode-block" id="predband"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.predband">[docs]</a><span class="k">def</span> <span class="nf">predband</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="n">yd</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">conf</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculates the prediction band of the linear regression model at the desired confidence</span>
<span class="sd">level, using analytical methods. </span>

<span class="sd">Clarification of the difference between confidence and prediction bands:</span>
<span class="sd">&quot;The 2sigma confidence interval is 95% sure to contain the best-fit regression line. </span>
<span class="sd">This is not the same as saying it will contain 95% of the data points. The prediction bands are</span>
<span class="sd">further from the best-fit line than the confidence bands, a lot further if you have many data </span>
<span class="sd">points. The 95% prediction interval is the area in which you expect 95% of all data points to fall.&quot;</span>
<span class="sd">(from http://graphpad.com/curvefit/linear_regression.htm)</span>

<span class="sd">Arguments:</span>

<span class="sd">- conf: desired confidence level, by default 0.95 (2 sigma)</span>
<span class="sd">- xd,yd: data arrays</span>
<span class="sd">- a,b: linear fit parameters as in y=ax+b</span>
<span class="sd">- x: (optional) array with x values to calculate the confidence band. If none is provided, will</span>
<span class="sd">  by default generate 100 points in the original x-range of the data.</span>
<span class="sd">  </span>
<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; lpb,upb,x=nemmen.predband(all.kp,all.lg,a,b,conf=0.95)</span>
<span class="sd">calculates the prediction bands for the given input arrays</span>

<span class="sd">&gt;&gt;&gt; pylab.fill_between(x, lpb, upb, alpha=0.3, facecolor=&#39;gray&#39;)</span>
<span class="sd">plots a shaded area containing the prediction band  </span>

<span class="sd">:returns: Sequence (lpb,upb,x) with the arrays holding the lower and upper confidence bands </span>
<span class="sd">corresponding to the [input] x array.</span>

<span class="sd">References:</span>

<span class="sd">1. `Introduction to Simple Linear Regression, Gerard </span>
<span class="sd">E. Dallal, Ph.D. &lt;http://www.JerryDallal.com/LHSP/slr.htm&gt;`_</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="o">-</span><span class="n">conf</span>	<span class="c1"># significance</span>
	<span class="n">n</span><span class="o">=</span><span class="n">xd</span><span class="o">.</span><span class="n">size</span>	<span class="c1"># data sample size</span>

	<span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span> <span class="n">x</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xd</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">xd</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">100</span><span class="p">)</span>

	<span class="c1"># Predicted values (best-fit model)</span>
	<span class="n">y</span><span class="o">=</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">b</span>

	<span class="c1"># Auxiliary definitions</span>
	<span class="n">sd</span><span class="o">=</span><span class="n">scatterfit</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="n">yd</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>	<span class="c1"># Scatter of data about the model</span>
	<span class="n">sxd</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">xd</span><span class="o">-</span><span class="n">xd</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">sx</span><span class="o">=</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">xd</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span>	<span class="c1"># array</span>

	<span class="c1"># Quantile of Student&#39;s t distribution for p=1-alpha/2</span>
	<span class="n">q</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mf">2.</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

	<span class="c1"># Prediction band</span>
	<span class="n">dy</span><span class="o">=</span><span class="n">q</span><span class="o">*</span><span class="n">sd</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="mf">1.</span><span class="o">+</span><span class="mf">1.</span><span class="o">/</span><span class="n">n</span> <span class="o">+</span> <span class="n">sx</span><span class="o">/</span><span class="n">sxd</span> <span class="p">)</span>
	<span class="n">upb</span><span class="o">=</span><span class="n">y</span><span class="o">+</span><span class="n">dy</span>	<span class="c1"># Upper prediction band</span>
	<span class="n">lpb</span><span class="o">=</span><span class="n">y</span><span class="o">-</span><span class="n">dy</span>	<span class="c1"># Lower prediction band</span>

	<span class="k">return</span> <span class="n">lpb</span><span class="p">,</span><span class="n">upb</span><span class="p">,</span><span class="n">x</span></div>
	



<div class="viewcode-block" id="confbandnl"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.confbandnl">[docs]</a><span class="k">def</span> <span class="nf">confbandnl</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="n">yd</span><span class="p">,</span><span class="n">fun</span><span class="p">,</span><span class="n">par</span><span class="p">,</span><span class="n">varcov</span><span class="p">,</span><span class="n">deg</span><span class="p">,</span><span class="n">conf</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculates the confidence band of a nonlinear model at the desired confidence</span>
<span class="sd">level, using analytical methods. </span>

<span class="sd">Arguments:</span>

<span class="sd">- xd,yd: data arrays</span>
<span class="sd">- fun : function f(v) - the model - which returns a scalar. v is an array</span>
<span class="sd">  such that v[0]=x (scalar), v[i&gt;0] = parameters of the model</span>
<span class="sd">- par : array or list with structure [par0, par1, par2, ...] with the best-fit</span>
<span class="sd">  parameters that will be fed into fun</span>
<span class="sd">- varcov : variance-covariance matrix obtained from the nonlinear fit</span>
<span class="sd">- deg : number of free parameters in the model</span>
<span class="sd">- conf: desired confidence level, by default 0.95 (2 sigma)</span>
<span class="sd">- x: (optional) array with x values to calculate the confidence band. If none is provided, will</span>
<span class="sd">  by default generate 100 points in the original x-range of the data.</span>
<span class="sd">  </span>
<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; lcb,ucb,x=nemmen.confbandnl(all.kp,all.lg,broken,bfit,bcov,4,conf=0.95)</span>
<span class="sd">calculates the confidence bands for the given input arrays</span>

<span class="sd">&gt;&gt;&gt; pylab.fill_between(x, lcb, ucb, alpha=0.3, facecolor=&#39;gray&#39;)</span>
<span class="sd">plots a shaded area containing the prediction band  </span>

<span class="sd">:returns: Sequence (lcb,ucb,x) with the arrays holding the lower and upper confidence bands </span>
<span class="sd">corresponding to the [input] x array.</span>

<span class="sd">References:</span>

<span class="sd">1. `How does Prism compute confidence and prediction bands for nonlinear regression? &lt;http://www.graphpad.com/faq/viewfaq.cfm?faq=1099&gt;`_</span>
<span class="sd">2. http://stats.stackexchange.com/questions/15423/how-to-compute-prediction-bands-for-non-linear-regression</span>
<span class="sd">3. see also my notebook</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="kn">import</span> <span class="nn">numdifftools</span>
	
	<span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="o">-</span><span class="n">conf</span>	<span class="c1"># significance</span>
	<span class="n">n</span><span class="o">=</span><span class="n">xd</span><span class="o">.</span><span class="n">size</span>	<span class="c1"># data sample size</span>

	<span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span> <span class="n">x</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xd</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">xd</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">100</span><span class="p">)</span>

	<span class="c1"># Gradient (needs to be evaluated)</span>
	<span class="n">dfun</span><span class="o">=</span><span class="n">numdifftools</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span><span class="n">fun</span><span class="p">)</span>
	
	<span class="c1"># Quantile of Student&#39;s t distribution for p=1-alpha/2</span>
	<span class="n">q</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mf">2.</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

	<span class="c1"># Residual sum of squares		</span>
	<span class="n">rss</span><span class="o">=</span><span class="n">residual</span><span class="p">(</span><span class="n">yd</span><span class="p">,</span> <span class="n">evalfun</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span><span class="n">xd</span><span class="p">,</span><span class="n">par</span><span class="p">)</span> <span class="p">)</span>
	
	<span class="n">grad</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="p">[],[]</span>
	<span class="n">i</span><span class="o">=</span><span class="mi">0</span>
	<span class="n">y</span><span class="o">=</span><span class="n">evalfun</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">par</span><span class="p">)</span>
	<span class="n">v</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
		<span class="c1"># List: arrays consisting of [x[i], par1, par2, ...]</span>
		<span class="n">p</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">par</span><span class="p">))</span> <span class="p">)</span>
	
		<span class="c1"># List: each element -&gt; gradient evaluated at each xi</span>
		<span class="n">grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfun</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
				
		<span class="c1"># Before processing the grad array, eliminates the first element</span>
		<span class="n">temp</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">varcov</span><span class="p">)</span>
		<span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span> <span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span>
		
	<span class="c1"># Confidence band</span>
	<span class="n">dy</span><span class="o">=</span><span class="n">q</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">v</span><span class="o">*</span><span class="n">rss</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">deg</span><span class="p">)</span> <span class="p">)</span>
	<span class="n">ucb</span><span class="o">=</span><span class="n">y</span><span class="o">+</span><span class="n">dy</span>	<span class="c1"># Upper confidence band</span>
	<span class="n">lcb</span><span class="o">=</span><span class="n">y</span><span class="o">-</span><span class="n">dy</span>	<span class="c1"># Lower confidence band</span>

	<span class="k">return</span> <span class="n">lcb</span><span class="p">,</span><span class="n">ucb</span><span class="p">,</span><span class="n">x</span></div>





<div class="viewcode-block" id="predbandnl"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.predbandnl">[docs]</a><span class="k">def</span> <span class="nf">predbandnl</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span><span class="n">yd</span><span class="p">,</span><span class="n">fun</span><span class="p">,</span><span class="n">par</span><span class="p">,</span><span class="n">varcov</span><span class="p">,</span><span class="n">deg</span><span class="p">,</span><span class="n">conf</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span><span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculates the prediction band of a nonlinear model at the desired confidence</span>
<span class="sd">level, using analytical methods. </span>

<span class="sd">Arguments:</span>

<span class="sd">- xd,yd: data arrays</span>
<span class="sd">- fun : function f(v) - the model - which returns a scalar. v is an array</span>
<span class="sd">  such that v[0]=x, v[i&gt;0] = parameters of the model</span>
<span class="sd">- par : array or list with structure [par0, par1, par2, ...] with the best-fit</span>
<span class="sd">  parameters that will be fed into fun</span>
<span class="sd">- varcov : variance-covariance matrix obtained from the nonlinear fit</span>
<span class="sd">- deg : number of free parameters in the model</span>
<span class="sd">- conf: desired confidence level, by default 0.95 (2 sigma)</span>
<span class="sd">- x: (optional) array with x values to calculate the confidence band. If none is provided, will</span>
<span class="sd">  by default generate 100 points in the original x-range of the data.</span>
<span class="sd">  </span>
<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; lpb,upb,x=nemmen.predbandnl(all.kp,all.lg,broken,bfit,bcov,4,conf=0.95)</span>
<span class="sd">calculates the prediction bands for the given input arrays</span>

<span class="sd">&gt;&gt;&gt; pylab.fill_between(x, lpb, upb, alpha=0.3, facecolor=&#39;gray&#39;)</span>
<span class="sd">plots a shaded area containing the prediction band  </span>

<span class="sd">:returns: Sequence (lpb,upb,x) with the arrays holding the lower and upper confidence bands </span>
<span class="sd">corresponding to the [input] x array.</span>

<span class="sd">References:</span>
<span class="sd">1. http://www.graphpad.com/faq/viewfaq.cfm?faq=1099, &quot;How does Prism compute confidence and prediction bands for nonlinear regression?&quot;</span>
<span class="sd">2. http://stats.stackexchange.com/questions/15423/how-to-compute-prediction-bands-for-non-linear-regression</span>
<span class="sd">3. see also my notebook)</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="kn">import</span> <span class="nn">numdifftools</span>
	
	<span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="o">-</span><span class="n">conf</span>	<span class="c1"># significance</span>
	<span class="n">n</span><span class="o">=</span><span class="n">xd</span><span class="o">.</span><span class="n">size</span>	<span class="c1"># data sample size</span>

	<span class="k">if</span> <span class="n">x</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span> <span class="n">x</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xd</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">xd</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="mi">100</span><span class="p">)</span>

	<span class="c1"># Gradient (needs to be evaluated)</span>
	<span class="n">dfun</span><span class="o">=</span><span class="n">numdifftools</span><span class="o">.</span><span class="n">Gradient</span><span class="p">(</span><span class="n">fun</span><span class="p">)</span>
	
	<span class="c1"># Quantile of Student&#39;s t distribution for p=1-alpha/2</span>
	<span class="n">q</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mf">2.</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

	<span class="c1"># Residual sum of squares		</span>
	<span class="n">rss</span><span class="o">=</span><span class="n">residual</span><span class="p">(</span><span class="n">yd</span><span class="p">,</span> <span class="n">evalfun</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span><span class="n">xd</span><span class="p">,</span><span class="n">par</span><span class="p">)</span> <span class="p">)</span>
	
	<span class="n">grad</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="p">[],[]</span>
	<span class="n">i</span><span class="o">=</span><span class="mi">0</span>
	<span class="n">y</span><span class="o">=</span><span class="n">evalfun</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">par</span><span class="p">)</span>
	<span class="n">v</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
		<span class="c1"># List: arrays consisting of [x[i], par1, par2, ...]</span>
		<span class="n">p</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(([</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span><span class="n">par</span><span class="p">))</span> <span class="p">)</span>
	
		<span class="c1"># List: each element -&gt; gradient evaluated at each xi</span>
		<span class="n">grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dfun</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
				
		<span class="c1"># Before processing the grad array, eliminates the first element</span>
		<span class="n">temp</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">varcov</span><span class="p">)</span>
		<span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span> <span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">:])</span>
		
	<span class="c1"># Confidence band</span>
	<span class="n">dy</span><span class="o">=</span><span class="n">q</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="p">(</span><span class="mf">1.</span><span class="o">+</span><span class="n">v</span><span class="p">)</span><span class="o">*</span><span class="n">rss</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">deg</span><span class="p">)</span> <span class="p">)</span>
	<span class="n">upb</span><span class="o">=</span><span class="n">y</span><span class="o">+</span><span class="n">dy</span>	<span class="c1"># Upper prediction band</span>
	<span class="n">lpb</span><span class="o">=</span><span class="n">y</span><span class="o">-</span><span class="n">dy</span>	<span class="c1"># Lower prediction band</span>

	<span class="k">return</span> <span class="n">lpb</span><span class="p">,</span><span class="n">upb</span><span class="p">,</span><span class="n">x</span></div>
		
	


<div class="viewcode-block" id="confbandmc"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.confbandmc">[docs]</a><span class="k">def</span> <span class="nf">confbandmc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">par</span><span class="p">,</span><span class="n">varcov</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">sigmas</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculates the 1sigma confidence band of a linear model without needing</span>
<span class="sd">to specify the data points, by doing a Monte Carlo simulation using the</span>
<span class="sd">Multivariate normal distribution. Assumes the parameters follow a 2D</span>
<span class="sd">normal distribution.</span>

<span class="sd">Arguments:</span>

<span class="sd">- x: array with x values to calculate the confidence band. </span>
<span class="sd">- par : array or list with structure [par0, par1, par2, ...] with the best-fit</span>
<span class="sd">  parameters</span>
<span class="sd">- varcov : variance-covariance matrix of the parameters</span>
<span class="sd">- n : number of (a,b) points generated from the multivariate gaussian</span>
<span class="sd">- sigmas : number of standard deviations contained within the prediction</span>
<span class="sd">  band</span>

<span class="sd">Output:</span>

<span class="sd">- lcb, ucb : lower and upper prediction bands</span>
<span class="sd">- y : values of the model tabulated at x</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; lcb,ucb,y=nemmen.confbandmc(x,bfit,bcov)</span>
<span class="sd">calculates the prediction bands for the given input arrays</span>

<span class="sd">&gt;&gt;&gt; pylab.fill_between(x, lcb, ucb, alpha=0.3, facecolor=&#39;gray&#39;)</span>
<span class="sd">plots a shaded area containing the prediction band</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c1"># Generates many realizations of a and b from the multinormal distribution</span>
	<span class="n">ar</span><span class="p">,</span><span class="n">br</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">par</span><span class="p">,</span><span class="n">varcov</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
	
	<span class="n">erry</span><span class="o">=</span><span class="p">[]</span>	<span class="c1"># will contain the std deviation in y</span>
	<span class="n">y</span><span class="o">=</span><span class="p">[]</span>	<span class="c1"># values of y for each x</span>
	
	<span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
		<span class="n">yr</span><span class="o">=</span><span class="n">ar</span><span class="o">*</span><span class="n">xi</span><span class="o">+</span><span class="n">br</span>
		<span class="n">erry</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">yr</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="p">)</span>
		<span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">yr</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="p">)</span>	
	
	<span class="n">erry</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">erry</span><span class="p">)</span>
	<span class="n">y</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

	<span class="n">ucb</span><span class="o">=</span><span class="n">y</span><span class="o">+</span><span class="n">sigmas</span><span class="o">*</span><span class="n">erry</span>	<span class="c1"># Upper confidence band</span>
	<span class="n">lcb</span><span class="o">=</span><span class="n">y</span><span class="o">-</span><span class="n">sigmas</span><span class="o">*</span><span class="n">erry</span>	<span class="c1"># Lower confidence band</span>

	<span class="k">return</span> <span class="n">lcb</span><span class="p">,</span><span class="n">ucb</span><span class="p">,</span><span class="n">y</span></div>
	
	
	
	
<div class="viewcode-block" id="credbandmc"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.credbandmc">[docs]</a><span class="k">def</span> <span class="nf">credbandmc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">slope</span><span class="p">,</span><span class="n">inter</span><span class="p">,</span><span class="n">sigmas</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculates the confidence (or credibility in case of Bayesian analysis) </span>
<span class="sd">band of a linear regression model, given the posterior probability distributions</span>
<span class="sd">of the slope and intercept (presumably computed via Bayesian regression,</span>
<span class="sd">see bayeslin.pro). These distributions do not need to be normal.</span>

<span class="sd">Arguments:</span>

<span class="sd">- x: array with x values to calculate the confidence band. </span>
<span class="sd">- slope, inter: posterior distributions of slope and intercept for linear</span>
<span class="sd">  regression</span>
<span class="sd">- sigmas : number of standard deviations contained within the confidence</span>
<span class="sd">  band</span>

<span class="sd">Output:</span>

<span class="sd">- lcb, ucb : lower and upper confidence bands</span>
<span class="sd">- y : best-fit values of the model tabulated at x</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; lcb,ucb,y=nemmen.predbandmc(x,a,b)</span>
<span class="sd">calculates the prediction bands for the given input arrays</span>

<span class="sd">&gt;&gt;&gt; pylab.fill_between(x, lcb, ucb, alpha=0.3, facecolor=&#39;gray&#39;)</span>
<span class="sd">plots a shaded area containing the prediction band</span>

<span class="sd">v1 Jun. 2012: inspired by private communication with B. Kelly.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">a</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="n">slope</span><span class="p">,</span><span class="n">inter</span>
	
	<span class="c1"># Define the confidence/credibility interval</span>
	<span class="n">conf</span><span class="o">=</span><span class="mf">1.</span><span class="o">-</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">sigmas</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span>
	
	<span class="n">lcb</span><span class="p">,</span><span class="n">ucb</span><span class="p">,</span><span class="n">ym</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">numpy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	
	<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> 
		<span class="c1"># Distribution of y for each x</span>
		<span class="n">yp</span><span class="o">=</span><span class="n">a</span><span class="o">*</span><span class="n">xi</span><span class="o">+</span><span class="n">b</span>	<span class="c1"># &#39;p&#39; as in posterior</span>
		
		<span class="c1"># Lower confidence band</span>
		<span class="n">lcb</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">scoreatpercentile</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span><span class="n">conf</span><span class="o">*</span><span class="mf">100.</span><span class="o">/</span><span class="mf">2.</span><span class="p">)</span>
		<span class="c1"># Upper confidence band</span>
		<span class="n">ucb</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">scoreatpercentile</span><span class="p">(</span><span class="n">yp</span><span class="p">,</span><span class="mf">100.</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">conf</span><span class="o">/</span><span class="mf">2.</span><span class="p">))</span>
		
		<span class="n">ym</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">yp</span><span class="p">)</span>	
		

	<span class="k">return</span> <span class="n">lcb</span><span class="p">,</span><span class="n">ucb</span><span class="p">,</span><span class="n">ym</span></div>
	
	
	
	
	

<div class="viewcode-block" id="gauss2d"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.gauss2d">[docs]</a><span class="k">def</span> <span class="nf">gauss2d</span><span class="p">(</span><span class="n">par</span><span class="p">,</span><span class="n">varcov</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Calculates random numbers drawn from the multinormal distribution in</span>
<span class="sd">two dimensions. Computes also the probability associated with each</span>
<span class="sd">number that can be used to computed confidence levels.</span>

<span class="sd">Arguments:</span>

<span class="sd">- par : array or list with structure [par0, par1, par2, ...] with the best-fit</span>
<span class="sd">  parameters</span>
<span class="sd">- varcov : variance-covariance matrix of the parameters</span>
<span class="sd">- n : number of (a,b) points generated from the multivariate gaussian</span>

<span class="sd">Output:</span>

<span class="sd">- x,y : arrays of random values generated from the multinormal distribution</span>
<span class="sd">- prob : probability associated with each value</span>

<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; x,y,prob=gauss2d(par,varcov,100000)</span>

<span class="sd">v1 Apr. 2012</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c1"># Generates many realizations of a and b from the multinormal distribution</span>
	<span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">par</span><span class="p">,</span><span class="n">varcov</span><span class="p">,</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
	
	<span class="c1"># Best-fit values</span>
	<span class="n">x0</span><span class="p">,</span><span class="n">y0</span> <span class="o">=</span> <span class="n">par</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
	
	<span class="n">dx</span><span class="p">,</span><span class="n">dy</span> <span class="o">=</span> <span class="n">x</span><span class="o">-</span><span class="n">x0</span><span class="p">,</span><span class="n">y</span><span class="o">-</span><span class="n">y0</span>
	<span class="n">sigx</span><span class="p">,</span><span class="n">sigy</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">varcov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]),</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">varcov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
	<span class="n">cov</span><span class="o">=</span><span class="n">varcov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
	<span class="n">rho</span><span class="o">=</span><span class="n">cov</span><span class="o">/</span><span class="n">sigx</span><span class="o">*</span><span class="n">sigy</span>
	
	<span class="n">numchisq</span><span class="o">=</span><span class="p">(</span><span class="n">dx</span><span class="o">/</span><span class="n">sigx</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="p">(</span><span class="n">dy</span><span class="o">/</span><span class="n">sigy</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mf">2.</span><span class="o">*</span><span class="n">rho</span><span class="o">*</span><span class="p">(</span><span class="n">dx</span><span class="o">/</span><span class="n">sigx</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">dy</span><span class="o">/</span><span class="n">sigy</span><span class="p">)</span>
	<span class="n">chisq</span><span class="o">=</span><span class="n">numchisq</span><span class="o">/</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">rho</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="n">prob</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">chisq</span><span class="o">/</span><span class="mf">2.</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">prob</span></div>




<div class="viewcode-block" id="bootcorr"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.bootcorr">[docs]</a><span class="k">def</span> <span class="nf">bootcorr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">nboot</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Given (X,Y) data points with intrinsic scatter, computes the </span>
<span class="sd">bootstrapped Pearson and Spearman correlation coefficients. This</span>
<span class="sd">will give you an idea of how much outliers affect your correlation.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; r,rho=bootcorr(x,y,100000)</span>

<span class="sd">performs 100000 bootstrapping realizations on the arrays x and y.</span>

<span class="sd">:returns: *r* - array with bootstrapped Pearson statistics</span>
<span class="sd">:returns: *rho* - bootstrapped array with Spearman statistics</span>

<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">r</span><span class="p">,</span><span class="n">rho</span><span class="o">=</span><span class="p">[],[]</span>
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nboot</span><span class="p">):</span>
		<span class="p">[</span><span class="n">xsim</span><span class="p">,</span><span class="n">ysim</span><span class="p">]</span><span class="o">=</span><span class="n">bootstrap</span><span class="p">([</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">])</span>
		
		<span class="c1"># Pearson r</span>
		<span class="n">rsim</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">xsim</span><span class="p">,</span><span class="n">ysim</span><span class="p">)</span>	
		<span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rsim</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
		
		<span class="c1"># Spearman rho</span>
		<span class="n">rhosim</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">xsim</span><span class="p">,</span><span class="n">ysim</span><span class="p">)</span>
		<span class="n">rho</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rhosim</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

	<span class="n">r</span><span class="p">,</span><span class="n">rho</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">r</span><span class="p">),</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rho</span><span class="p">)</span>

	<span class="n">results</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="n">numpy</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">r</span><span class="p">),</span> <span class="n">r</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">rho</span><span class="p">),</span> <span class="n">rho</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="p">])</span>
	<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&lt;r&gt;    err_r &lt;rho&gt; errrho&quot;</span><span class="p">)</span>
	<span class="nb">print</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

	<span class="n">results</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="n">r2p</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="o">-</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">std</span><span class="p">()),</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">r2p</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">r</span><span class="p">),</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">r2p</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">r</span><span class="p">)</span><span class="o">+</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">std</span><span class="p">()),</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="p">])</span>
	<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prob. &lt;- &lt;r&gt;-std,  &lt;r&gt;,    &lt;r&gt;+std&quot;</span><span class="p">)</span>
	<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

	<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Rejection of H0 respectively at&quot;</span><span class="p">)</span>
	<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
		<span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">p2sig</span><span class="p">(</span><span class="n">p</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>	<span class="p">)</span>
		
	<span class="k">return</span> <span class="n">r</span><span class="p">,</span><span class="n">rho</span></div>


















	
	
	
<span class="c1"># Comparing goodness-of-fit of different models</span>
<span class="c1"># ================================================</span>
<span class="c1"># F-test, Akaike information criterion and reduced chi-squared	</span>

<div class="viewcode-block" id="ftest"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.ftest">[docs]</a><span class="k">def</span> <span class="nf">ftest</span><span class="p">(</span><span class="n">rss1</span><span class="p">,</span><span class="n">rss2</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">p1</span><span class="p">,</span><span class="n">p2</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Carries out the F-test to decide which model fits the data better.</span>
<span class="sd">Computes the F statistic, associated p-value and the significance</span>
<span class="sd">in sigmas with which we can reject the null hypothesis. You can also</span>
<span class="sd">give the chisq^2 values instead of RSS if you have y-errors.</span>

<span class="sd">Note that p2&gt;p1 must be obeyed, i.e. model 2 is &quot;nested&quot; within model</span>
<span class="sd">1.</span>

<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; fstat,pvalue,conf = ftest(rss1,rss2,n,p1,p2)</span>

<span class="sd">Arguments:</span>
<span class="sd">- rss1, rss2 : residual sum of squares for models 1 and 2</span>
<span class="sd">- n : sample size, i.e. number of data points</span>
<span class="sd">- p1, p2 : number of free parameters in the models</span>

<span class="sd">Returns:</span>
<span class="sd">- fstat : the F statistic</span>
<span class="sd">- pvalue : p-value associated with the F statistic</span>
<span class="sd">- conf : significance in sigmas with which we can reject the null hypothesis</span>

<span class="sd">References:</span>
<span class="sd">1. http://en.wikipedia.org/wiki/F-test</span>
<span class="sd">2. http://graphpad.com/curvefit/2_models__1_dataset.htm, Graphpad.com, </span>
<span class="sd">  Comparing the fits of two models (CurveFit.com)</span>

<span class="sd">v1 Dec. 2011</span>
<span class="sd">v2 Jan 16 2012: added comment regarding y-errors</span>
<span class="sd">&quot;&quot;&quot;</span>
	<span class="n">fstat</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">f_value</span><span class="p">(</span><span class="n">rss1</span><span class="p">,</span><span class="n">rss2</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="n">p1</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="n">p2</span><span class="p">)</span>
	<span class="n">pvalue</span><span class="o">=</span><span class="mf">1.</span><span class="o">-</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">fstat</span><span class="p">,</span><span class="n">p2</span><span class="o">-</span><span class="n">p1</span><span class="p">,</span><span class="n">n</span><span class="o">-</span><span class="n">p2</span><span class="p">)</span>
	<span class="n">conf</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">pvalue</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">fstat</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">conf</span></div>
	
	



<div class="viewcode-block" id="aic"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.aic">[docs]</a><span class="k">def</span> <span class="nf">aic</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">rss</span><span class="p">,</span><span class="n">errors</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Computes the Akaike information criterion which is &quot;a measure of the relative goodness of</span>
<span class="sd">fit of a statistical model&quot;. Unlike the F-test, it does not assume that one model is </span>
<span class="sd">a particular case of the more complex one. If errors==False then assume the</span>
<span class="sd">errors are the same for every data point. Otherwise, assumes you are providing</span>
<span class="sd">the chi-squared values instead of RSS.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; aic = aic(k,n,rss)</span>

<span class="sd">:param rss: residual sum of squares for the model in case errors=False, otherwise assumes you are giving the chi-square values</span>
<span class="sd">:param n: sample size, i.e. number of data points</span>
<span class="sd">:param k: number of free parameters in the model</span>
<span class="sd">:returns: AIC statistic</span>

<span class="sd">References:</span>

<span class="sd">1. Documentation for Origin software on fit comparison: http://www.originlab.com/index.aspx?go=Products/Origin/DataAnalysis/CurveFitting/NonlinearFitting&amp;pid=1195 (first heard about this test there)</span>
<span class="sd">2. http://en.wikipedia.org/wiki/Akaike_information_criterion</span>

<span class="sd">v1 Dec 2011</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="k">if</span> <span class="n">errors</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
		<span class="c1"># AIC assuming the errors are identical and given the residual sum of squares,</span>
		<span class="c1"># see http://en.wikipedia.org/wiki/Akaike_information_criterion#Relevance_to_chi-squared_fitting</span>
		<span class="n">aicstat</span><span class="o">=</span><span class="n">n</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rss</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">+</span><span class="mf">2.</span><span class="o">*</span><span class="n">k</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="c1"># If you have different errors for the data points, it will assume rss=chisq</span>
		<span class="n">aicstat</span><span class="o">=</span><span class="n">rss</span><span class="o">+</span><span class="mf">2.</span><span class="o">*</span><span class="n">k</span>
			
	<span class="c1"># AICc = AIC with a correction for finite sample size</span>
	<span class="n">aicc</span><span class="o">=</span><span class="n">aicstat</span><span class="o">+</span><span class="mf">2.</span><span class="o">*</span><span class="n">k</span><span class="o">*</span><span class="p">(</span><span class="n">k</span><span class="o">+</span><span class="mf">1.</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="o">-</span><span class="mf">1.</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">aicc</span></div>
	
	
	

<div class="viewcode-block" id="bic"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.bic">[docs]</a><span class="k">def</span> <span class="nf">bic</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">rss</span><span class="p">,</span><span class="n">errors</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Computes the Bayesian information criterion which is &quot;a criterion for model selection</span>
<span class="sd">among a finite set of models&quot;. From wikipedia: &quot;The BIC [...] introduces a </span>
<span class="sd">penalty term for the number of parameters in the model. The penalty term is larger </span>
<span class="sd">in BIC than in AIC.&quot;</span>

<span class="sd">In order to use BIC to quantify the evidence against a specific model, check out</span>
<span class="sd">the section &quot;use of BIC&quot; in the presentation &quot;171:290 Model Selection, Lecture VI: </span>
<span class="sd">The Bayesian Information Criterion&quot; by Joseph Cavanaugh </span>
<span class="sd">(http://myweb.uiowa.edu/cavaaugh/ms_lec_6_ho.pdf).</span>

<span class="sd">If errors==False then assume the errors are the same for every data point. </span>
<span class="sd">Otherwise, assumes you are providing the chi-squared values instead of RSS.</span>

<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; bic = bic(k,n,rss)</span>

<span class="sd">Arguments:</span>
<span class="sd">- rss : residual sum of squares for the model in case errors=False, otherwise</span>
<span class="sd">	assumes you are giving the chi-square values</span>
<span class="sd">- n : sample size, i.e. number of data points</span>
<span class="sd">- k : number of free parameters in the model</span>

<span class="sd">Returns: BIC statistic</span>

<span class="sd">References:</span>
<span class="sd">1. http://en.wikipedia.org/wiki/Bayesian_information_criterion</span>
<span class="sd">2. Model Selection, Lecture VI: The Bayesian Information Criterion&quot; by Joseph </span>
<span class="sd">  Cavanaugh (http://myweb.uiowa.edu/cavaaugh/ms_lec_6_ho.pdf)</span>

<span class="sd">v1 Apr 2012</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="k">if</span> <span class="n">errors</span><span class="o">==</span><span class="kc">False</span><span class="p">:</span>
		<span class="c1"># BIC assuming the errors are identical and given the residual sum of squares,</span>
		<span class="c1"># using the unbiased variance</span>
		<span class="n">bicstat</span><span class="o">=</span><span class="n">n</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rss</span><span class="o">/</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mf">1.</span><span class="p">))</span><span class="o">+</span><span class="n">k</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="c1"># If you have different errors for the data points, it will assume rss=chisq</span>
		<span class="n">bicstat</span><span class="o">=</span><span class="n">rss</span><span class="o">+</span><span class="n">k</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">bicstat</span></div>
	
	



<div class="viewcode-block" id="redchisq"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.redchisq">[docs]</a><span class="k">def</span> <span class="nf">redchisq</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">a</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">sd</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Returns the reduced chi-square error statistic for a linear fit:</span>
<span class="sd">  chisq/nu</span>
<span class="sd">where nu is the number of degrees of freedom. If individual standard deviations </span>
<span class="sd">(array sd) are supplied, then the chi-square error statistic is computed as the </span>
<span class="sd">sum of squared errors divided by the standard deviations. </span>
<span class="sd">See http://en.wikipedia.org/wiki/Goodness_of_fit for reference.</span>
<span class="sd">	</span>
<span class="sd">If a linear model is not provided via A,B (y=ax+b) then the method computes</span>
<span class="sd">the chi-square using the best-fit line.</span>

<span class="sd">x,y,sd assumed to be Numpy arrays. a,b scalars. deg integer.</span>
<span class="sd">Returns the float chisq/nu with the reduced chi-square statistic.</span>
<span class="sd">	&quot;&quot;&quot;</span>

	<span class="k">if</span> <span class="n">a</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>	
		<span class="c1"># Performs linear regression</span>
		<span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
	
	<span class="c1"># Chi-square statistic</span>
	<span class="k">if</span> <span class="n">sd</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">((</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="n">sd</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
		
	<span class="c1"># Number of degrees of freedom assuming 2 free parameters</span>
	<span class="n">nu</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="o">-</span><span class="mi">3</span>
	
	<span class="k">return</span> <span class="n">chisq</span><span class="o">/</span><span class="n">nu</span></div>
	



<div class="viewcode-block" id="redchisqxy"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.redchisqxy">[docs]</a><span class="k">def</span> <span class="nf">redchisqxy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Returns the reduced chi-square error statistic for a linear fit:</span>
<span class="sd">  chisq/nu</span>
<span class="sd">where nu is the number of degrees of freedom. The chi-square statistic is</span>
<span class="sd">computed taking into account the errors in both X and Y (i.e. the</span>
<span class="sd">effective variance). See equation 3 in Ascenso et al. 2012, A&amp;A or</span>
<span class="sd">Yee &amp; Ellingson 2003 ApJ.</span>

<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; chisq=redchisqxy(xdata,ydata,errx,erry,a,b)</span>
<span class="sd">where</span>
<span class="sd">  xdata,ydata : data</span>
<span class="sd">  errx,erry : measurement uncertainties in the data</span>
<span class="sd">  a,b : slope and intercept of the best-fit linear regression model</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">sdsq</span><span class="o">=</span><span class="n">erry</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">a</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">errx</span><span class="o">**</span><span class="mi">2</span>
	<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="n">x</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">sdsq</span> <span class="p">)</span>
		
	<span class="c1"># Number of degrees of freedom assuming 2 free parameters</span>
	<span class="n">nu</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="o">-</span><span class="mi">3</span>
	
	<span class="k">return</span> <span class="n">chisq</span><span class="o">/</span><span class="n">nu</span></div>





<div class="viewcode-block" id="redchisqg"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.redchisqg">[docs]</a><span class="k">def</span> <span class="nf">redchisqg</span><span class="p">(</span><span class="n">ydata</span><span class="p">,</span><span class="n">ymod</span><span class="p">,</span><span class="n">deg</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">sd</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Returns the reduced chi-square error statistic for an arbitrary model, </span>
<span class="sd">chisq/nu, where nu is the number of degrees of freedom. If individual </span>
<span class="sd">standard deviations (array sd) are supplied, then the chi-square error </span>
<span class="sd">statistic is computed as the sum of squared errors divided by the standard </span>
<span class="sd">deviations. See http://en.wikipedia.org/wiki/Goodness_of_fit for reference.</span>

<span class="sd">ydata,ymod,sd assumed to be Numpy arrays. deg integer.</span>

<span class="sd">Usage:</span>
<span class="sd">&gt;&gt;&gt; chisq=redchisqg(ydata,ymod,n,sd)</span>
<span class="sd">where</span>
<span class="sd">  ydata : data</span>
<span class="sd">  ymod : model evaluated at the same x points as ydata</span>
<span class="sd">  n : number of free parameters in the model</span>
<span class="sd">  sd : uncertainties in ydata</span>
<span class="sd">  	&quot;&quot;&quot;</span>
	<span class="c1"># Chi-square statistic</span>
	<span class="k">if</span> <span class="n">sd</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">ydata</span><span class="o">-</span><span class="n">ymod</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">chisq</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">((</span><span class="n">ydata</span><span class="o">-</span><span class="n">ymod</span><span class="p">)</span><span class="o">/</span><span class="n">sd</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
		
	<span class="c1"># Number of degrees of freedom assuming 2 free parameters</span>
	<span class="n">nu</span><span class="o">=</span><span class="n">ydata</span><span class="o">.</span><span class="n">size</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">deg</span>
	
	<span class="k">return</span> <span class="n">chisq</span><span class="o">/</span><span class="n">nu</span>	</div>


<div class="viewcode-block" id="r2"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.r2">[docs]</a><span class="k">def</span> <span class="nf">r2</span><span class="p">(</span><span class="n">ydata</span><span class="p">,</span><span class="n">ymod</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Computes the &quot;coefficient of determination&quot; R^2. According to wikipedia,</span>
<span class="sd">&quot;It is the proportion of variability in a data set that is accounted for </span>
<span class="sd">by the statistical model. It provides a measure of how well future outcomes </span>
<span class="sd">are likely to be predicted by the model.&quot;</span>

<span class="sd">This method was inspired by http://stackoverflow.com/questions/3460357/calculating-the-coefficient-of-determination-in-python</span>

<span class="sd">References:</span>
<span class="sd">1. http://en.wikipedia.org/wiki/Coefficient_of_determination</span>
<span class="sd">2. http://stackoverflow.com/questions/3460357/calculating-the-coefficient-of-determination-in-python</span>

<span class="sd">v1 Apr 18th 2012</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">ss_tot</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">ydata</span><span class="o">-</span><span class="n">ydata</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
	<span class="n">ss_err</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span> <span class="p">(</span><span class="n">ydata</span><span class="o">-</span><span class="n">ymod</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
	
	<span class="k">return</span> <span class="mf">1.</span><span class="o">-</span><span class="n">ss_err</span><span class="o">/</span><span class="n">ss_tot</span></div>



<div class="viewcode-block" id="fitstats"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.fitstats">[docs]</a><span class="k">def</span> <span class="nf">fitstats</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Computes different useful statistics for the given (X +- errX, Y +- errY)</span>
<span class="sd">arrays of data. Also quantifies the goodness-of-fit of the provided</span>
<span class="sd">linear fit with slope &#39;a&#39; and intercept &#39;b&#39;.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; r,rho,rchisq,scat,iscat,r2=fitstats(xdata,ydata,errx,erry,a,b)</span>

<span class="sd">  :param xdata,ydata: data</span>
<span class="sd">  :param errx,erry: measurement uncertainties in the data</span>
<span class="sd">  :param a,b: slope and intercept of the best-fit linear regression model</span>
<span class="sd">  </span>
<span class="sd">Returns:</span>

<span class="sd">	- Pearson &#39;r&#39;</span>
<span class="sd">	- Spearman &#39;rho&#39;</span>
<span class="sd">	- Reduced chi-squared &#39;chi^2_nu&#39;</span>
<span class="sd">	- raw scatter about the best-fit</span>
<span class="sd">	- intrinsic scatter</span>
<span class="sd">	- Coefficient of determination &#39;R^2&#39;</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c1"># Pearson r</span>
	<span class="n">r</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">)</span>	
	<span class="c1"># Spearman rho</span>
	<span class="n">rho</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">)</span>	
	<span class="c1"># Reduced chi-squared</span>
	<span class="n">rchisq</span><span class="o">=</span><span class="n">redchisqxy</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
	<span class="c1"># raw scatter</span>
	<span class="n">scat</span><span class="o">=</span><span class="n">scatpratt</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
	<span class="c1"># intrinsic scatter	</span>
	<span class="n">iscat</span><span class="o">=</span><span class="n">intscat</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="n">ydata</span><span class="p">,</span><span class="n">errx</span><span class="p">,</span><span class="n">erry</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>	
	<span class="c1"># Coefficient of determination R^2</span>
	<span class="n">rtwo</span><span class="o">=</span><span class="n">r2</span><span class="p">(</span><span class="n">ydata</span><span class="p">,</span><span class="n">a</span><span class="o">*</span><span class="n">xdata</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">r</span><span class="p">,</span><span class="n">rho</span><span class="p">,</span><span class="n">rchisq</span><span class="p">,</span><span class="n">scat</span><span class="p">,</span><span class="n">iscat</span><span class="p">,</span><span class="n">rtwo</span></div>


















<span class="c1"># Operations on statistical distributions</span>
<span class="c1"># =======================================</span>
<span class="c1">#</span>

<div class="viewcode-block" id="splitstd"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.splitstd">[docs]</a><span class="k">def</span> <span class="nf">splitstd</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Given the input distribution, this method computes two standard deviations:</span>
<span class="sd">the left and right side spreads. This is especially useful if you are dealing</span>
<span class="sd">with a split normal distribution from your data and you want to quantify the</span>
<span class="sd">lower and upper error bars without having to fit a split normal distribution.</span>

<span class="sd">This is a quick nonparametric method, as opposed to the more computationally</span>
<span class="sd">intensive minimization involved when fitting a function.</span>

<span class="sd">Algorithm:</span>

<span class="sd">- divide the original distribution in two distributions at the mode</span>
<span class="sd">- create two new distributions, which are the symmetrical versions of the left and right side of the original one</span>
<span class="sd">- compute the standard deviations for the new mirror distributions</span>

<span class="sd">:param x: array or list containing the distribution</span>
<span class="sd">:returns: left.stddev, right.stddev</span>

<span class="sd">.. note:: do not forget to inspect *x*.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c1">#med=median(x)</span>
	<span class="n">med</span><span class="o">=</span><span class="n">mode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

	<span class="n">x1</span><span class="o">=</span><span class="n">x</span><span class="p">[</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;</span><span class="n">med</span><span class="p">)</span> <span class="p">]</span> <span class="c1"># left side</span>
	<span class="n">x1mirror</span><span class="o">=</span><span class="n">x1</span><span class="o">+</span><span class="mf">2.</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x1</span><span class="o">-</span><span class="n">med</span><span class="p">)</span> <span class="c1"># mirror side</span>
	<span class="n">x1new</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span><span class="n">x1mirror</span><span class="p">))</span>

	<span class="n">x2</span><span class="o">=</span><span class="n">x</span><span class="p">[</span> <span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span><span class="o">&gt;=</span><span class="n">med</span><span class="p">)</span> <span class="p">]</span> <span class="c1"># right side</span>
	<span class="n">x2mirror</span><span class="o">=</span><span class="n">x2</span><span class="o">-</span><span class="mf">2.</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x2</span><span class="o">-</span><span class="n">med</span><span class="p">)</span> <span class="c1"># mirror side</span>
	<span class="n">x2new</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">x2</span><span class="p">,</span><span class="n">x2mirror</span><span class="p">))</span>

	<span class="k">return</span> <span class="n">x1new</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">x2new</span><span class="o">.</span><span class="n">std</span><span class="p">()</span></div>




<div class="viewcode-block" id="mode"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.mode">[docs]</a><span class="k">def</span> <span class="nf">mode</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Finds the mode of a distribution, i.e. the value where the PDF peaks.</span>

<span class="sd">:param x: input list/array with the distribution</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">yh</span><span class="p">,</span><span class="n">xh</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
	<span class="n">dxh</span><span class="o">=</span><span class="p">(</span><span class="n">xh</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">xh</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mf">2.</span>
	<span class="n">xh</span><span class="o">=</span><span class="n">xh</span><span class="o">+</span><span class="n">dxh</span>

	<span class="k">return</span> <span class="n">xh</span><span class="p">[</span> <span class="n">search</span><span class="p">(</span><span class="n">yh</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span><span class="n">yh</span><span class="p">)</span> <span class="p">]</span></div>















<span class="c1"># Custom statistical distributions</span>
<span class="c1"># ==================================</span>
<span class="c1">#</span>

	
<div class="viewcode-block" id="random_normal"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.random_normal">[docs]</a><span class="k">def</span> <span class="nf">random_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span><span class="n">std</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Returns an array of n elements of random variables, following a normal </span>
<span class="sd">distribution with the supplied mean and standard deviation.</span>

<span class="sd">.. warning:: this is superseded. Use `numpy.random.normal &lt;https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html&gt;`_ instead.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="k">return</span> <span class="n">std</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">+</span><span class="n">mean</span></div>
	




<div class="viewcode-block" id="randomvariate"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.randomvariate">[docs]</a><span class="k">def</span> <span class="nf">randomvariate</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">xmax</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Rejection method for random number generation:</span>
<span class="sd">Uses the rejection method for generating random numbers derived from an arbitrary </span>
<span class="sd">probability distribution. For reference, see Bevington&#39;s book, page 84. Based on</span>
<span class="sd">rejection*.py.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; randomvariate(P,N,xmin,xmax)</span>

<span class="sd">  where</span>

<span class="sd">:param P: probability distribution function from which you want to generate random numbers</span>
<span class="sd">:param N: desired number of random values</span>
<span class="sd">:param xmin,xmax: range of random numbers desired</span>
<span class="sd">  </span>
<span class="sd">:returns: the sequence (ran,ntrials) where</span>
<span class="sd">  	ran : array of shape N with the random variates that follow the input P</span>
<span class="sd">  	ntrials : number of trials the code needed to achieve N</span>

<span class="sd">Here is the algorithm:</span>

<span class="sd">- generate x&#39; in the desired range</span>
<span class="sd">- generate y&#39; between Pmin and Pmax (Pmax is the maximal value of your pdf)</span>
<span class="sd">- if y&#39;&lt;P(x&#39;) accept x&#39;, otherwise reject</span>
<span class="sd">- repeat until desired number is achieved</span>

<span class="sd">v1 Nov. 2011</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="c1"># Calculates the minimal and maximum values of the PDF in the desired</span>
	<span class="c1"># interval. The rejection method needs these values in order to work</span>
	<span class="c1"># properly.</span>
	<span class="n">x</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span><span class="n">xmax</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
	<span class="n">y</span><span class="o">=</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
	<span class="n">pmin</span><span class="o">=</span><span class="mf">0.</span>
	<span class="n">pmax</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

	<span class="c1"># Counters</span>
	<span class="n">naccept</span><span class="o">=</span><span class="mi">0</span>
	<span class="n">ntrial</span><span class="o">=</span><span class="mi">0</span>

	<span class="c1"># Keeps generating numbers until we achieve the desired n</span>
	<span class="n">ran</span><span class="o">=</span><span class="p">[]</span>	<span class="c1"># output list of random numbers</span>
	<span class="k">while</span> <span class="n">naccept</span><span class="o">&lt;</span><span class="n">n</span><span class="p">:</span>
		<span class="n">x</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span><span class="n">xmax</span><span class="p">)</span>	<span class="c1"># x&#39;</span>
		<span class="n">y</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">pmin</span><span class="p">,</span><span class="n">pmax</span><span class="p">)</span>	<span class="c1"># y&#39;</span>

		<span class="k">if</span> <span class="n">y</span><span class="o">&lt;</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
			<span class="n">ran</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
			<span class="n">naccept</span><span class="o">=</span><span class="n">naccept</span><span class="o">+</span><span class="mi">1</span>
		<span class="n">ntrial</span><span class="o">=</span><span class="n">ntrial</span><span class="o">+</span><span class="mi">1</span>
	
	<span class="n">ran</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ran</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">ran</span><span class="p">,</span><span class="n">ntrial</span></div>



<div class="viewcode-block" id="random"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.random">[docs]</a><span class="k">def</span> <span class="nf">random</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Generates an array of random uniformly distributed floats in the </span>
<span class="sd">interval *[x0,x1)*.</span>

<span class="sd">&gt;&gt;&gt; random(0.3,0.4,1000)</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="k">return</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">scipy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span></div>






<div class="viewcode-block" id="splitnorm"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.splitnorm">[docs]</a><span class="k">def</span> <span class="nf">splitnorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">sig1</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span><span class="n">sig2</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span><span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Split normal distribution (or asymmetric gaussian) PDF. Useful when dealing</span>
<span class="sd">with asymmetric error bars.</span>

<span class="sd">See http://en.wikipedia.org/wiki/Split_normal_distribution.</span>

<span class="sd">:param x: input array where the PDF will be computed</span>
<span class="sd">:param sig1: left standard deviation</span>
<span class="sd">:param sig2: right std. dev.</span>
<span class="sd">:param mu: mode</span>
<span class="sd">:returns: probability distribution function for the array x</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">const</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">sig1</span> <span class="o">+</span> <span class="n">sig2</span><span class="p">)</span>
    
	<span class="n">p</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;</span><span class="n">mu</span><span class="p">,</span> 
		<span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.</span><span class="o">*</span><span class="n">sig1</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">*</span><span class="n">const</span><span class="p">,</span> 
		<span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.</span><span class="o">*</span><span class="n">sig2</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">*</span><span class="n">const</span><span class="p">)</span>
    
	<span class="k">return</span> <span class="n">p</span></div>



<div class="viewcode-block" id="splitnorm_gen"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.splitnorm_gen">[docs]</a><span class="k">class</span> <span class="nc">splitnorm_gen</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">rv_continuous</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Split normal distribution defined using scipy.stats. Can be called as </span>
<span class="sd">any scipy.stats distribution. I took the effort of defining the extra</span>
<span class="sd">CDF and PPF methods below in order to speedup calls to this class </span>
<span class="sd">(I have particularly in mind the package *mcerp*).</span>

<span class="sd">:param x: input array where the PDF will be computed</span>
<span class="sd">:param sig1: left standard deviation</span>
<span class="sd">:param sig2: right std. dev.</span>
<span class="sd">:param mu: mode</span>

<span class="sd">Examples</span>
<span class="sd">----------</span>

<span class="sd">Defines distribution with sig1=1, sig2=3, mu=0:</span>

<span class="sd">&gt;&gt;&gt; split = splitnorm_gen(name=&#39;splitnorm&#39;, shapes=&#39;sig1, sig2, mu&#39;)</span>
<span class="sd">&gt;&gt;&gt; s=split(1,3,0.0001)</span>
<span class="sd">&gt;&gt;&gt; x=numpy.linspace(-10,10,100)</span>

<span class="sd">Computes PDF:</span>

<span class="sd">&gt;&gt;&gt; s.pdf(x)</span>

<span class="sd">Computes CDF:</span>

<span class="sd">&gt;&gt;&gt; s.cdf(x)</span>

<span class="sd">Generates 100 random numbers:</span>

<span class="sd">&gt;&gt;&gt; s.rvs(100)</span>

<span class="sd">.. warning:: for some reason, this fails if mu=0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">sig1</span><span class="p">,</span> <span class="n">sig2</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
        <span class="n">const</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">sig1</span> <span class="o">+</span> <span class="n">sig2</span><span class="p">)</span>
            
        <span class="n">p</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;=</span><span class="n">mu</span><span class="p">,</span> 
                <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.</span><span class="o">*</span><span class="n">sig1</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">*</span><span class="n">const</span><span class="p">,</span> 
                <span class="n">numpy</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mf">2.</span><span class="o">*</span><span class="n">sig2</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span><span class="o">*</span><span class="n">const</span><span class="p">)</span>
                      
        <span class="k">return</span> <span class="n">p</span>
    
    <span class="k">def</span> <span class="nf">_cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">sig1</span><span class="p">,</span> <span class="n">sig2</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
        <span class="n">const</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="p">(</span><span class="n">sig1</span><span class="o">+</span><span class="n">sig2</span><span class="p">)</span>
        
        <span class="n">c</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span><span class="o">&lt;=</span><span class="n">mu</span><span class="p">,</span> 
                <span class="n">sig1</span><span class="o">*</span><span class="n">const</span><span class="o">*</span><span class="p">(</span><span class="mf">1.</span><span class="o">+</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erf</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">sig1</span><span class="p">))),</span> 
                <span class="n">const</span><span class="o">*</span><span class="p">(</span><span class="n">sig1</span><span class="o">+</span><span class="n">sig2</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erf</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">sig2</span><span class="p">)))</span>
                <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">c</span>
    
    <span class="k">def</span> <span class="nf">_ppf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">sig1</span><span class="p">,</span><span class="n">sig2</span><span class="p">,</span><span class="n">mu</span><span class="p">):</span>
        <span class="n">nu</span><span class="o">=</span><span class="n">sig1</span><span class="o">/</span><span class="p">(</span><span class="n">sig1</span> <span class="o">+</span> <span class="n">sig2</span><span class="p">)</span>
        
        <span class="n">pf</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">q</span><span class="o">&lt;=</span><span class="n">nu</span><span class="p">,</span> 
                <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">sig1</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">((</span><span class="n">sig1</span> <span class="o">+</span> <span class="n">sig2</span><span class="p">)</span><span class="o">/</span><span class="n">sig1</span><span class="o">*</span><span class="n">q</span> <span class="o">-</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span><span class="p">,</span> 
                <span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">sig2</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(((</span><span class="n">sig1</span> <span class="o">+</span> <span class="n">sig2</span><span class="p">)</span><span class="o">*</span><span class="n">q</span> <span class="o">-</span> <span class="n">sig1</span><span class="p">)</span><span class="o">/</span><span class="n">sig2</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span>
                <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">pf</span>     
    
    <span class="k">def</span> <span class="nf">_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sig1</span><span class="p">,</span> <span class="n">sig2</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
        <span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="o">+</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">sig2</span> <span class="o">-</span> <span class="n">sig1</span><span class="p">)</span>
        <span class="n">var</span><span class="o">=</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="mf">2.</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">sig2</span><span class="o">-</span><span class="n">sig1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">sig1</span><span class="o">*</span><span class="n">sig2</span>
        <span class="n">skew</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">sig2</span><span class="o">-</span><span class="n">sig1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span> <span class="p">(</span><span class="mf">4.</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">pi</span><span class="o">-</span><span class="mf">1.</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">sig2</span><span class="o">-</span><span class="n">sig1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="n">sig1</span><span class="o">*</span><span class="n">sig2</span> <span class="p">)</span>
        <span class="n">kurt</span><span class="o">=</span><span class="kc">None</span>
        
        <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">skew</span><span class="p">,</span> <span class="n">kurt</span></div>






















<span class="c1"># p-values and significance</span>
<span class="c1"># ===========================</span>
<span class="c1">#</span>


<div class="viewcode-block" id="r2p"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.r2p">[docs]</a><span class="k">def</span> <span class="nf">r2p</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">n</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Given a value of the Pearson r coefficient, this method gives the</span>
<span class="sd">corresponding p-value of the null hypothesis (i.e. no correlation).</span>

<span class="sd">Code copied from scipy.stats.pearsonr source.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; p=r2p(r,n)</span>

<span class="sd">where &#39;r&#39; is the Pearson coefficient and n is the number of data</span>
<span class="sd">points.</span>

<span class="sd">:returns: p-value of the null hypothesis.</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">df</span> <span class="o">=</span> <span class="n">n</span><span class="o">-</span><span class="mi">2</span>
	<span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
		<span class="n">prob</span> <span class="o">=</span> <span class="mf">0.0</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">t_squared</span> <span class="o">=</span> <span class="n">r</span><span class="o">*</span><span class="n">r</span> <span class="o">*</span> <span class="p">(</span><span class="n">df</span> <span class="o">/</span> <span class="p">((</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">r</span><span class="p">)))</span>
		<span class="n">prob</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">betai</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">df</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">df</span> <span class="o">/</span> <span class="p">(</span><span class="n">df</span> <span class="o">+</span> <span class="n">t_squared</span><span class="p">))</span>
        
	<span class="k">return</span> <span class="n">prob</span></div>



<div class="viewcode-block" id="p2sig"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.p2sig">[docs]</a><span class="k">def</span> <span class="nf">p2sig</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Given the p-value Pnull (i.e. probability of the null hypothesis) below, </span>
<span class="sd">evaluates the confidence level with which we can reject the hypothesis in standard </span>
<span class="sd">deviations.</span>

<span class="sd">Inspired on prob2sig.nb.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; s=p2sig(0.001)</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">sig</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(</span><span class="mf">1.</span><span class="o">-</span><span class="n">p</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">sig</span></div>



<div class="viewcode-block" id="conf2sig"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.conf2sig">[docs]</a><span class="k">def</span> <span class="nf">conf2sig</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Given a confidence p-value, translates it into standard deviations.</span>
<span class="sd">E.g., p=0.683 -&gt; 1sigma, p=0.954 -&gt; 2sigma, etc.</span>

<span class="sd">Inspired on p2sig method.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; s=conf2sig(0.683)</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="n">sig</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
	
	<span class="k">return</span> <span class="n">sig</span></div>



<div class="viewcode-block" id="sig2conf"><a class="viewcode-back" href="../../nmmn.html#nmmn.stats.sig2conf">[docs]</a><span class="k">def</span> <span class="nf">sig2conf</span><span class="p">(</span><span class="n">sig</span><span class="p">):</span>
	<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Given a number of std. deviations, translates it into a p-value.</span>
<span class="sd">E.g., 1sigma -&gt; p=0.683, 2sigma -&gt; p=0.954, etc.</span>

<span class="sd">Inspired on p2sig method.</span>

<span class="sd">Usage:</span>

<span class="sd">&gt;&gt;&gt; s=sig2conf(5.)</span>
<span class="sd">	&quot;&quot;&quot;</span>
	<span class="k">return</span> <span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">sig</span><span class="o">/</span><span class="n">numpy</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span></div>
	

	
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Author.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
    </div>

    

    
  </body>
</html>